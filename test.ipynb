{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3708b952",
   "metadata": {},
   "source": [
    "### rocket science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bb583",
   "metadata": {},
   "source": [
    "### to rewrite the cell below, bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5781fb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Board quad not detected reliably. Tune canny/area/approx parameters or improve lighting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 1) Calibrate board & masks\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m     27\u001b[0m cfg \u001b[38;5;241m=\u001b[39m CalibCFG(video_path\u001b[38;5;241m=\u001b[39mvideo_path, warp_size\u001b[38;5;241m=\u001b[39mwarp_size, show_debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, save_debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m H, _ \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_homography\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m inner_box \u001b[38;5;241m=\u001b[39m estimate_inner_box_median(video_path, H, cfg)\n\u001b[1;32m     30\u001b[0m outer_mask, inner_mask, ring_mask, dice_roi, dice_roi_mask \u001b[38;5;241m=\u001b[39m build_masks(warp_size, inner_box)\n",
      "File \u001b[0;32m~/cv/monopoly/detect_board.py:139\u001b[0m, in \u001b[0;36mestimate_homography\u001b[0;34m(video_path, cfg)\u001b[0m\n\u001b[1;32m    136\u001b[0m         quads\u001b[38;5;241m.\u001b[39mappend(q)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(quads) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoard quad not detected reliably. Tune canny/area/approx parameters or improve lighting.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    143\u001b[0m quad_med \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(np\u001b[38;5;241m.\u001b[39mstack(quads, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    144\u001b[0m s \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mwarp_size\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Board quad not detected reliably. Tune canny/area/approx parameters or improve lighting."
     ]
    }
   ],
   "source": [
    "# --- Pawn detection w/ estimated BG (memory-safe) + choose frame index ---\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detect_board import (\n",
    "    CalibCFG, estimate_homography, estimate_inner_box_median, build_masks,\n",
    "    warp_board, diff_warped_vs_bg_clean\n",
    ")\n",
    "from detect_pawns import PawnCFG, detect_pawns_from_diff\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Inputs you control\n",
    "# ----------------------------\n",
    "video_path = \"data/easy/3_easy.mp4\"   # <-- change\n",
    "warp_size  = 900                      # <-- your project warp size\n",
    "\n",
    "frame_idx_to_detect = 0       # <-- YOU set this (0-based)\n",
    "bg_start_frame = 0                    # <-- optional: where BG sampling starts\n",
    "# ----------------------------\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Calibrate board & masks\n",
    "# ----------------------------\n",
    "cfg = CalibCFG(video_path=video_path, warp_size=warp_size, show_debug=False, save_debug=False)\n",
    "H, _ = estimate_homography(video_path, cfg)\n",
    "inner_box = estimate_inner_box_median(video_path, H, cfg)\n",
    "outer_mask, inner_mask, ring_mask, dice_roi, dice_roi_mask = build_masks(warp_size, inner_box)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Memory-safe background estimation (keeps only K cleanest frames)\n",
    "# ----------------------------\n",
    "def compute_clean_background_light(\n",
    "    video_path: str,\n",
    "    H: np.ndarray,\n",
    "    warp_size: int,\n",
    "    *,\n",
    "    roi_mask: np.ndarray | None = None,\n",
    "    start_frame: int = 0,\n",
    "    n_samples: int = 180,\n",
    "    stride: int = 5,\n",
    "    keep_k: int = 30,\n",
    "    mog2_history: int = 300,\n",
    "    mog2_varThreshold: int = 14,\n",
    "    open_k: int = 3,\n",
    "    close_k: int = 9,\n",
    "    min_visible_count: int = 4,\n",
    "):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    # Seek to deterministic starting point\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(start_frame))\n",
    "\n",
    "    mog = cv2.createBackgroundSubtractorMOG2(\n",
    "        history=mog2_history,\n",
    "        varThreshold=mog2_varThreshold,\n",
    "        detectShadows=False\n",
    "    )\n",
    "\n",
    "    heap = []  # (-ratio, warped_bgr, fg_u8)\n",
    "\n",
    "    roi_denom = float(np.count_nonzero(roi_mask)) if roi_mask is not None else None\n",
    "    if roi_mask is not None and roi_denom == 0:\n",
    "        raise ValueError(\"roi_mask has zero area\")\n",
    "\n",
    "    i = 0\n",
    "    collected = 0\n",
    "    while collected < n_samples:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        if i % stride == 0:\n",
    "            warped = warp_board(frame, H, warp_size)\n",
    "\n",
    "            fg = mog.apply(warped)\n",
    "            fg = (fg > 0).astype(np.uint8) * 255\n",
    "\n",
    "            if open_k > 1:\n",
    "                k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (open_k, open_k))\n",
    "                fg = cv2.morphologyEx(fg, cv2.MORPH_OPEN, k, iterations=1)\n",
    "            if close_k > 1:\n",
    "                k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (close_k, close_k))\n",
    "                fg = cv2.morphologyEx(fg, cv2.MORPH_CLOSE, k, iterations=1)\n",
    "\n",
    "            if roi_mask is not None:\n",
    "                fg_roi = cv2.bitwise_and(fg, fg, mask=roi_mask)\n",
    "                ratio = float(np.count_nonzero(fg_roi)) / roi_denom\n",
    "            else:\n",
    "                ratio = float(np.count_nonzero(fg)) / float(fg.size)\n",
    "\n",
    "            item = (-ratio, warped, fg)\n",
    "\n",
    "            if len(heap) < keep_k:\n",
    "                heapq.heappush(heap, item)\n",
    "            else:\n",
    "                # replace worst if current is cleaner\n",
    "                if item[0] > heap[0][0]:\n",
    "                    heapq.heapreplace(heap, item)\n",
    "\n",
    "            collected += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(heap) < max(10, keep_k // 2):\n",
    "        raise RuntimeError(f\"Too few frames kept for BG (kept={len(heap)}). Lower keep_k/stride or increase n_samples.\")\n",
    "\n",
    "    kept = sorted([(-nr, fr, fg) for (nr, fr, fg) in heap], key=lambda x: x[0])\n",
    "    frames_k = np.stack([x[1] for x in kept], axis=0).astype(np.uint8)  # (k,H,W,3)\n",
    "    fgs_k    = np.stack([x[2] for x in kept], axis=0).astype(np.uint8)  # (k,H,W)\n",
    "\n",
    "    mask_bg = (fgs_k == 0)\n",
    "    visible_count = mask_bg.sum(axis=0)\n",
    "\n",
    "    bg = np.zeros_like(frames_k[0], dtype=np.uint8)\n",
    "    for c in range(3):\n",
    "        vals = frames_k[..., c].astype(np.float32)\n",
    "        vals[~mask_bg] = np.nan\n",
    "        med = np.nanmedian(vals, axis=0)\n",
    "        bg[..., c] = np.nan_to_num(med, nan=0).astype(np.uint8)\n",
    "\n",
    "    holes = (visible_count < int(min_visible_count)).astype(np.uint8) * 255\n",
    "    if np.count_nonzero(holes) > 0:\n",
    "        bg = cv2.inpaint(bg, holes, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return bg\n",
    "\n",
    "bg_clean = compute_clean_background_light(\n",
    "    video_path, H, warp_size,\n",
    "    roi_mask=ring_mask,         # focus on pawn ring stability\n",
    "    start_frame=bg_start_frame, # YOU control this too\n",
    "    n_samples=180,\n",
    "    stride=3,\n",
    "    keep_k=30,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Read the exact frame you want\n",
    "# ----------------------------\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_idx_to_detect))\n",
    "ok, frame_bgr = cap.read()\n",
    "cap.release()\n",
    "if not ok:\n",
    "    raise RuntimeError(f\"Could not read frame index {frame_idx_to_detect} from {video_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Diff + pawn detection\n",
    "# ----------------------------\n",
    "diff_bgr, _ = diff_warped_vs_bg_clean(\n",
    "    frame_bgr, H, warp_size, bg_clean,\n",
    "    to_gray=False,\n",
    "    return_stats=False\n",
    ")\n",
    "\n",
    "pawns, fg_mask, dbg = detect_pawns_from_diff(\n",
    "    diff_bgr,\n",
    "    ring_mask=ring_mask,\n",
    "    prev_centers=None,\n",
    "    cfg=PawnCFG(),\n",
    ")\n",
    "\n",
    "print(\"Frame:\", frame_idx_to_detect)\n",
    "print(\"Pawns:\", pawns)\n",
    "print(\"Thr:\", dbg[\"thr\"], \"Contours:\", dbg[\"n_contours\"], \"Candidates:\", dbg[\"n_candidates\"])\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Viz (single figure)\n",
    "# ----------------------------\n",
    "warped = warp_board(frame_bgr, H, warp_size)\n",
    "\n",
    "viz = warped.copy()\n",
    "for i, p in enumerate(pawns):\n",
    "    x1, y1, x2, y2 = p[\"bbox\"]\n",
    "    cv2.rectangle(viz, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cx, cy = p[\"center\"]\n",
    "    cv2.circle(viz, (int(cx), int(cy)), 6, (0, 255, 0), -1)\n",
    "    cv2.putText(viz, f\"pawn{i+1}\", (x1, max(12, y1 - 6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.suptitle(f\"Pawn detection @ frame {frame_idx_to_detect}\")\n",
    "plt.subplot(1,2,1); plt.title(\"Warped + overlay\"); plt.imshow(cv2.cvtColor(viz, cv2.COLOR_BGR2RGB)); plt.axis(\"off\")\n",
    "plt.subplot(1,2,2); plt.title(\"FG mask (ring)\"); plt.imshow(fg_mask, cmap=\"gray\"); plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874391c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009f783ca3314e0fa3a605f21731fcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='video', layout=Layout(width='80%'), options=('data/difficu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8372ac17504edfa1b76a288d87698a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Interactive: pick video + frame, warp board using your calibration, detect cards only in inner field ---\n",
    "\n",
    "import os, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib.util\n",
    "from dataclasses import asdict\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# -------- load your script as a module --------\n",
    "SCRIPT_PATH = \"detect_board.py\"  # provided path\n",
    "spec = importlib.util.spec_from_file_location(\"detect_board\", SCRIPT_PATH)\n",
    "detect_board = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(detect_board)\n",
    "\n",
    "\n",
    "\n",
    "CalibCFG = detect_board.CalibCFG\n",
    "\n",
    "# -------- utilities --------\n",
    "def bgr_to_rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def show_bgr(img, title=None, figsize=(10,6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    if title: plt.title(title)\n",
    "    plt.imshow(bgr_to_rgb(img))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def show_gray(img, title=None, figsize=(10,4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    if title: plt.title(title)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def list_videos(root=\"data/easy\"):\n",
    "    exts = (\"*.mp4\", \"*.mov\", \"*.mkv\", \"*.avi\", \"*.m4v\")\n",
    "    out = []\n",
    "    for ext in exts:\n",
    "        out += glob.glob(os.path.join(root, \"**\", ext), recursive=True)\n",
    "    out = sorted(out)\n",
    "    return out\n",
    "\n",
    "def get_video_meta(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        raise RuntimeError(f\"Cannot open video: {video_path}\")\n",
    "    nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS) or 0.0)\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)\n",
    "    cap.release()\n",
    "    return nframes, fps, w, h\n",
    "\n",
    "def read_frame_at(video_path, idx):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        cap.release()\n",
    "        raise RuntimeError(f\"Cannot open video: {video_path}\")\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ok or frame is None:\n",
    "        raise RuntimeError(f\"Cannot read frame {idx} from {video_path}\")\n",
    "    return frame\n",
    "\n",
    "# -------- card detection limited to inner crop --------\n",
    "def detect_cards_in_crop(\n",
    "    crop_bgr,\n",
    "    *,\n",
    "    blur_ksize=5,\n",
    "    canny1=60,\n",
    "    canny2=160,\n",
    "    dilate_iter=1,\n",
    "    erode_iter=0,\n",
    "    min_area=2000,\n",
    "    max_area=200000,\n",
    "    min_aspect=0.55,\n",
    "    max_aspect=1.8,\n",
    "    approx_eps_frac=0.02,\n",
    "    use_hsv_filter=True,\n",
    "    h_min=0, h_max=179,\n",
    "    s_min=0, s_max=255,\n",
    "    v_min=0, v_max=255,\n",
    "    hsv_keep_ratio_min=0.15,\n",
    "):\n",
    "    img = crop_bgr.copy()\n",
    "    k = int(blur_ksize)\n",
    "    if k % 2 == 0: k += 1\n",
    "    k = max(3, k)\n",
    "    blurred = cv2.GaussianBlur(img, (k, k), 0)\n",
    "\n",
    "    edges = cv2.Canny(blurred, int(canny1), int(canny2))\n",
    "    morph = edges.copy()\n",
    "    if dilate_iter > 0:\n",
    "        morph = cv2.dilate(morph, None, iterations=int(dilate_iter))\n",
    "    if erode_iter > 0:\n",
    "        morph = cv2.erode(morph, None, iterations=int(erode_iter))\n",
    "\n",
    "    cnts, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv_mask = None\n",
    "    if use_hsv_filter:\n",
    "        lower = np.array([h_min, s_min, v_min], dtype=np.uint8)\n",
    "        upper = np.array([h_max, s_max, v_max], dtype=np.uint8)\n",
    "        hsv_mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    boxes, quads = [], []\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < min_area or area > max_area:\n",
    "            continue\n",
    "\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, float(approx_eps_frac) * peri, True)\n",
    "        if len(approx) != 4 or not cv2.isContourConvex(approx):\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(approx)\n",
    "        if w <= 0 or h <= 0:\n",
    "            continue\n",
    "        asp = w / float(h)\n",
    "        if not (min_aspect <= asp <= max_aspect):\n",
    "            continue\n",
    "\n",
    "        if use_hsv_filter and hsv_mask is not None:\n",
    "            quad_mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillConvexPoly(quad_mask, approx.reshape(-1, 2), 255)\n",
    "            inside = cv2.bitwise_and(hsv_mask, hsv_mask, mask=quad_mask)\n",
    "            keep_ratio = (inside > 0).sum() / max(1, (quad_mask > 0).sum())\n",
    "            if keep_ratio < hsv_keep_ratio_min:\n",
    "                continue\n",
    "\n",
    "        boxes.append((x, y, w, h))\n",
    "        quads.append(approx)\n",
    "\n",
    "    overlay = img.copy()\n",
    "    cv2.drawContours(overlay, quads, -1, (0,255,0), 2)\n",
    "    for (x,y,w,h) in boxes:\n",
    "        cv2.rectangle(overlay, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "\n",
    "    dbg = {\"edges\": edges, \"morph\": morph, \"hsv_mask\": hsv_mask, \"overlay\": overlay}\n",
    "    return boxes, quads, dbg\n",
    "\n",
    "\n",
    "# -------- calibration cache per video --------\n",
    "_calib_cache = {}\n",
    "\n",
    "def get_or_build_calibration(video_path, warp_size=900, show_debug=False):\n",
    "    key = (video_path, warp_size)\n",
    "    if key in _calib_cache:\n",
    "        return _calib_cache[key]\n",
    "\n",
    "    cfg = CalibCFG(video_path=video_path, warp_size=warp_size, show_debug=show_debug, save_debug=False)\n",
    "\n",
    "    # 1) estimate board homography\n",
    "    H, quad_med = detect_board.estimate_homography(video_path, cfg)\n",
    "\n",
    "    # 2) estimate inner box\n",
    "    inner_box = detect_board.estimate_inner_box_median(video_path, H, cfg)\n",
    "\n",
    "    # 3) build masks (we mainly need inner_box)\n",
    "    outer_mask, inner_mask, ring_mask, dice_roi, dice_roi_mask = detect_board.build_masks(warp_size, inner_box)\n",
    "\n",
    "    calib = {\n",
    "        \"cfg\": cfg,\n",
    "        \"H\": H,\n",
    "        \"quad_med\": quad_med,\n",
    "        \"inner_box\": inner_box,\n",
    "        \"inner_mask\": inner_mask,\n",
    "        \"ring_mask\": ring_mask\n",
    "    }\n",
    "    _calib_cache[key] = calib\n",
    "    return calib\n",
    "\n",
    "\n",
    "# -------- UI --------\n",
    "videos = list_videos(\"data\")\n",
    "if not videos:\n",
    "    raise RuntimeError(\"No videos found under data/. Put your mp4 in data/...\")\n",
    "\n",
    "w_video = widgets.Dropdown(\n",
    "    options=videos,\n",
    "    value=videos[0],\n",
    "    description=\"video\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "w_warp = widgets.IntSlider(value=900, min=600, max=1400, step=50, description=\"warp\")\n",
    "\n",
    "# detection knobs\n",
    "w_blur = widgets.IntSlider(value=5, min=3, max=21, step=2, description=\"blur\")\n",
    "w_c1 = widgets.IntSlider(value=60, min=0, max=300, step=1, description=\"canny1\")\n",
    "w_c2 = widgets.IntSlider(value=160, min=0, max=400, step=1, description=\"canny2\")\n",
    "w_dil = widgets.IntSlider(value=1, min=0, max=10, step=1, description=\"dilate\")\n",
    "w_ero = widgets.IntSlider(value=0, min=0, max=10, step=1, description=\"erode\")\n",
    "w_eps = widgets.FloatSlider(value=0.02, min=0.001, max=0.08, step=0.001, description=\"eps\")\n",
    "\n",
    "w_minA = widgets.IntSlider(value=2000, min=0, max=400000, step=200, description=\"min_area\")\n",
    "w_maxA = widgets.IntSlider(value=200000, min=1000, max=2500000, step=2000, description=\"max_area\")\n",
    "w_minAsp = widgets.FloatSlider(value=0.55, min=0.1, max=3.0, step=0.01, description=\"min_aspect\")\n",
    "w_maxAsp = widgets.FloatSlider(value=1.8, min=0.1, max=5.0, step=0.01, description=\"max_aspect\")\n",
    "\n",
    "w_useHSV = widgets.Checkbox(value=True, description=\"HSV filter\")\n",
    "w_hmin = widgets.IntSlider(value=0, min=0, max=179, step=1, description=\"H min\")\n",
    "w_hmax = widgets.IntSlider(value=179, min=0, max=179, step=1, description=\"H max\")\n",
    "w_smin = widgets.IntSlider(value=0, min=0, max=255, step=1, description=\"S min\")\n",
    "w_smax = widgets.IntSlider(value=255, min=0, max=255, step=1, description=\"S max\")\n",
    "w_vmin = widgets.IntSlider(value=0, min=0, max=255, step=1, description=\"V min\")\n",
    "w_vmax = widgets.IntSlider(value=255, min=0, max=255, step=1, description=\"V max\")\n",
    "w_keep = widgets.FloatSlider(value=0.15, min=0.0, max=1.0, step=0.01, description=\"HSV keep%\")\n",
    "\n",
    "w_view = widgets.Dropdown(\n",
    "    options=[\"warped+inner\", \"crop overlay\", \"edges\", \"morph\", \"hsv_mask\"],\n",
    "    value=\"crop overlay\",\n",
    "    description=\"view\"\n",
    ")\n",
    "\n",
    "w_frame = widgets.IntSlider(value=0, min=0, max=1, step=1, description=\"frame\")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "def _refresh_frame_slider(*_):\n",
    "    try:\n",
    "        nframes, fps, vw, vh = get_video_meta(w_video.value)\n",
    "    except Exception as e:\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            print(e)\n",
    "        return\n",
    "\n",
    "    # set a sane max\n",
    "    if nframes <= 0:\n",
    "        nframes = 3000\n",
    "    w_frame.max = max(0, nframes - 1)\n",
    "    w_frame.value = min(w_frame.value, w_frame.max)\n",
    "\n",
    "_refresh_frame_slider()\n",
    "\n",
    "def _run(*_):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        video_path = w_video.value\n",
    "        warp_size = int(w_warp.value)\n",
    "\n",
    "        # build or reuse calibration for this video\n",
    "        try:\n",
    "            calib = get_or_build_calibration(video_path, warp_size=warp_size, show_debug=False)\n",
    "        except Exception as e:\n",
    "            print(\"Calibration failed:\", e)\n",
    "            print(\"Tip: tune CalibCFG knobs in your script if needed (canny/area/approx).\")\n",
    "            return\n",
    "\n",
    "        H = calib[\"H\"]\n",
    "        inner_box = calib[\"inner_box\"]\n",
    "        xl, yt, xr, yb = inner_box\n",
    "\n",
    "        # read chosen frame\n",
    "        try:\n",
    "            frame = read_frame_at(video_path, int(w_frame.value))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return\n",
    "\n",
    "        warped = detect_board.warp_board(frame, H, warp_size)\n",
    "        crop = warped[yt:yb, xl:xr].copy()\n",
    "\n",
    "        # detect only inside inner crop\n",
    "        boxes, quads, dbg = detect_cards_in_crop(\n",
    "            crop,\n",
    "            blur_ksize=w_blur.value,\n",
    "            canny1=w_c1.value,\n",
    "            canny2=w_c2.value,\n",
    "            dilate_iter=w_dil.value,\n",
    "            erode_iter=w_ero.value,\n",
    "            approx_eps_frac=w_eps.value,\n",
    "            min_area=w_minA.value,\n",
    "            max_area=w_maxA.value,\n",
    "            min_aspect=w_minAsp.value,\n",
    "            max_aspect=w_maxAsp.value,\n",
    "            use_hsv_filter=w_useHSV.value,\n",
    "            h_min=w_hmin.value, h_max=w_hmax.value,\n",
    "            s_min=w_smin.value, s_max=w_smax.value,\n",
    "            v_min=w_vmin.value, v_max=w_vmax.value,\n",
    "            hsv_keep_ratio_min=w_keep.value,\n",
    "        )\n",
    "\n",
    "        # draw detections back onto warped\n",
    "        warped_overlay = warped.copy()\n",
    "        # inner box\n",
    "        cv2.rectangle(warped_overlay, (xl, yt), (xr, yb), (0, 255, 255), 2)\n",
    "\n",
    "        # offset crop detections into warped coords\n",
    "        for q in quads:\n",
    "            q2 = q.copy()\n",
    "            q2[:, 0, 0] += xl\n",
    "            q2[:, 0, 1] += yt\n",
    "            cv2.drawContours(warped_overlay, [q2], -1, (0, 255, 0), 2)\n",
    "\n",
    "        for (x,y,w,h) in boxes:\n",
    "            cv2.rectangle(warped_overlay, (xl+x, yt+y), (xl+x+w, yt+y+h), (255, 0, 0), 2)\n",
    "\n",
    "        print(f\"Video: {video_path}\")\n",
    "        print(f\"Frame: {w_frame.value}\")\n",
    "        print(f\"Inner box (xl,yt,xr,yb): {inner_box}\")\n",
    "        print(f\"Detections in inner field: {len(boxes)}\")\n",
    "\n",
    "        view = w_view.value\n",
    "        if view == \"warped+inner\":\n",
    "            show_bgr(warped_overlay, \"Warped board + inner box + detections\", figsize=(9,9))\n",
    "        elif view == \"crop overlay\":\n",
    "            show_bgr(dbg[\"overlay\"], \"Inner crop detections overlay\", figsize=(9,6))\n",
    "        elif view == \"edges\":\n",
    "            show_gray(dbg[\"edges\"], \"Inner crop Canny edges\")\n",
    "        elif view == \"morph\":\n",
    "            show_gray(dbg[\"morph\"], \"Inner crop edges after morphology\")\n",
    "        else:\n",
    "            if dbg[\"hsv_mask\"] is None:\n",
    "                print(\"HSV mask disabled.\")\n",
    "            else:\n",
    "                show_gray(dbg[\"hsv_mask\"], \"Inner crop HSV inRange mask\")\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([w_video, w_warp]),\n",
    "    w_frame,\n",
    "    widgets.HBox([w_view, w_useHSV]),\n",
    "    widgets.HBox([w_blur, w_c1, w_c2]),\n",
    "    widgets.HBox([w_dil, w_ero, w_eps]),\n",
    "    widgets.HBox([w_minA, w_maxA]),\n",
    "    widgets.HBox([w_minAsp, w_maxAsp]),\n",
    "    widgets.HBox([w_hmin, w_hmax]),\n",
    "    widgets.HBox([w_smin, w_smax]),\n",
    "    widgets.HBox([w_vmin, w_vmax]),\n",
    "    w_keep,\n",
    "])\n",
    "\n",
    "def _on_video_change(*_):\n",
    "    _refresh_frame_slider()\n",
    "    _run()\n",
    "\n",
    "w_video.observe(_on_video_change, names=\"value\")\n",
    "w_warp.observe(_on_video_change, names=\"value\")\n",
    "\n",
    "for w in [w_frame, w_view, w_useHSV, w_blur, w_c1, w_c2, w_dil, w_ero, w_eps,\n",
    "          w_minA, w_maxA, w_minAsp, w_maxAsp,\n",
    "          w_hmin, w_hmax, w_smin, w_smax, w_vmin, w_vmax, w_keep]:\n",
    "    w.observe(_run, names=\"value\")\n",
    "\n",
    "display(ui, out)\n",
    "_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84353b",
   "metadata": {},
   "source": [
    "### cards detection correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "296ce720",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m vw \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(out_path, fourcc, fps, (WARP_SIZE, WARP_SIZE))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     ok, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Run card detection (STRICTLY detect_cards.py logic) on a video and save annotated warped video ---\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from detect_board import CalibCFG, estimate_homography, estimate_inner_box_median, warp_board\n",
    "from detect_cards import CardDetectCFG, detect_cards_in_inner_field\n",
    "\n",
    "# ============\n",
    "# CONFIG\n",
    "# ============\n",
    "VIDEO_PATH = \"data/easy/2_easy.mp4\"   # <- set this\n",
    "WARP_SIZE  = 900                     # keep same as your board warp convention\n",
    "OUT_DIR    = \"out_cards\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "out_path = os.path.join(OUT_DIR, os.path.splitext(os.path.basename(VIDEO_PATH))[0] + \"_cards_annotated_warped.mp4\")\n",
    "\n",
    "# ============\n",
    "# CALIBRATION (frame -> warped) + inner box\n",
    "# ============\n",
    "cfg_calib = CalibCFG(video_path=VIDEO_PATH, warp_size=WARP_SIZE, show_debug=False, save_debug=False)\n",
    "H, _ = estimate_homography(VIDEO_PATH, cfg_calib)\n",
    "inner_box = estimate_inner_box_median(VIDEO_PATH, H, cfg_calib)\n",
    "\n",
    "# ============\n",
    "# CARD DETECTION CONFIG (defaults from detect_cards.py)\n",
    "# ============\n",
    "cfg_cards = CardDetectCFG()  # uses the file's default parameters\n",
    "\n",
    "# ============\n",
    "# PROCESS VIDEO\n",
    "# ============\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps <= 0:\n",
    "    fps = 30.0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "vw = cv2.VideoWriter(out_path, fourcc, fps, (WARP_SIZE, WARP_SIZE))\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    warped = warp_board(frame, H, WARP_SIZE)\n",
    "\n",
    "    # STRICT: detect directly on warped crop, no background subtraction\n",
    "    det = detect_cards_in_inner_field(warped, inner_box, cfg=cfg_cards)\n",
    "\n",
    "    # Draw boxes/quads exactly using detect_cards.py helpers (+ inner box)\n",
    "    overlay = det.draw_on_warped(warped, inner_box=inner_box, draw_inner_box=True)\n",
    "\n",
    "    vw.write(overlay)\n",
    "\n",
    "cap.release()\n",
    "vw.release()\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"inner_box:\", inner_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908da395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab57a8bbc11c4d7fac5d2daf6a41e2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(IntSlider(value=0, continuous_update=False, description='frame', max=3000), Chec…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d42e77e582b4c9780ebf46fb07885be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Interactive debug: tune dice + pips parameters on a single frame (IMPROVED) ---\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from detect_board import CalibCFG, estimate_homography, estimate_inner_box_median, warp_board\n",
    "\n",
    "from detect_dice import (\n",
    "    DiceRegionCFG,\n",
    "    TopFaceCropCFG,\n",
    "    PipCountCFG,\n",
    "    detect_dice_in_inner_field,\n",
    "    read_top_face_pips,\n",
    "    draw_dice_on_warped,\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 0) Set your video here\n",
    "# ======================\n",
    "VIDEO_PATH = \"data/easy/2_easy.mp4\"  # <- change this\n",
    "WARP_SIZE = 900\n",
    "\n",
    "# ======================\n",
    "# 1) One-time calibration\n",
    "# ======================\n",
    "cfg_calib = CalibCFG(video_path=VIDEO_PATH, warp_size=WARP_SIZE, show_debug=False, save_debug=False)\n",
    "H, _ = estimate_homography(VIDEO_PATH, cfg_calib)\n",
    "inner_box = estimate_inner_box_median(VIDEO_PATH, H, cfg_calib)\n",
    "\n",
    "def get_warped_frame(frame_idx: int):\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Could not open video: {VIDEO_PATH}\")\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_idx))\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    if not ok:\n",
    "        raise RuntimeError(f\"Could not read frame {frame_idx}\")\n",
    "    return warp_board(frame, H, WARP_SIZE)\n",
    "\n",
    "# ======================\n",
    "# 2) Widgets\n",
    "# ======================\n",
    "frame_idx_w = widgets.IntSlider(value=0, min=0, max=3000, step=1, description=\"frame\", continuous_update=False)\n",
    "\n",
    "# Dice region (inner field) detection params (better defaults for tiny dice)\n",
    "ab_thr_w   = widgets.IntSlider(value=38,  min=10, max=80, step=1, description=\"region ab_thr\", continuous_update=False)\n",
    "L_min_w    = widgets.IntSlider(value=170, min=50, max=245, step=1, description=\"region L_min\", continuous_update=False)\n",
    "L_q_w      = widgets.IntSlider(value=92,  min=50, max=99, step=1, description=\"region L_q\", continuous_update=False)\n",
    "open_k_w   = widgets.IntSlider(value=5,   min=1, max=31, step=2, description=\"region open_k\", continuous_update=False)\n",
    "close_k_w  = widgets.IntSlider(value=13,  min=1, max=51, step=2, description=\"region close_k\", continuous_update=False)\n",
    "close_it_w = widgets.IntSlider(value=1,   min=1, max=6,  step=1, description=\"region close_it\", continuous_update=False)\n",
    "\n",
    "min_area_w  = widgets.FloatSlider(value=0.00025, min=0.00005, max=0.01, step=0.00005,\n",
    "                                  description=\"min_area_frac\", readout_format=\".5f\", continuous_update=False)\n",
    "max_area_w  = widgets.FloatSlider(value=0.06, min=0.01, max=0.30, step=0.01,\n",
    "                                  description=\"max_area_frac\", readout_format=\".2f\", continuous_update=False)\n",
    "max_aspect_w = widgets.FloatSlider(value=1.35, min=1.05, max=3.00, step=0.05,\n",
    "                                   description=\"max_aspect\", readout_format=\".2f\", continuous_update=False)\n",
    "pad_frac_w = widgets.FloatSlider(value=0.06, min=0.00, max=0.20, step=0.01,\n",
    "                                 description=\"pad_frac\", readout_format=\".2f\", continuous_update=False)\n",
    "\n",
    "# New: rotation-invariant square checks\n",
    "use_rot_w = widgets.Checkbox(value=True, description=\"use_rotated_rect\")\n",
    "max_rot_aspect_w = widgets.FloatSlider(value=1.25, min=1.00, max=2.00, step=0.05,\n",
    "                                       description=\"max_rot_aspect\", readout_format=\".2f\", continuous_update=False)\n",
    "min_extent_w = widgets.FloatSlider(value=0.55, min=0.10, max=0.95, step=0.05,\n",
    "                                   description=\"min_extent\", readout_format=\".2f\", continuous_update=False)\n",
    "require_quad_w = widgets.Checkbox(value=False, description=\"require_quad_like\")\n",
    "\n",
    "# Selection / scoring\n",
    "keep_top_k_w = widgets.IntSlider(value=2, min=1, max=4, step=1, description=\"keep_top_k\", continuous_update=False)\n",
    "max_score_cand_w = widgets.IntSlider(value=12, min=1, max=30, step=1, description=\"max_to_score\", continuous_update=False)\n",
    "score_with_pips_w = widgets.Checkbox(value=True, description=\"score_with_pips\")\n",
    "\n",
    "# Top-face crop params (used before pip counting)\n",
    "tf_ab_thr_w   = widgets.IntSlider(value=35,  min=10, max=80, step=1, description=\"face ab_thr\", continuous_update=False)\n",
    "tf_L_min_w    = widgets.IntSlider(value=175, min=50, max=245, step=1, description=\"face L_min\", continuous_update=False)\n",
    "tf_L_q_w      = widgets.IntSlider(value=94,  min=50, max=99, step=1, description=\"face L_q\", continuous_update=False)\n",
    "tf_open_w     = widgets.IntSlider(value=7,   min=1, max=31, step=2, description=\"face open_k\", continuous_update=False)\n",
    "tf_close_w    = widgets.IntSlider(value=15,  min=1, max=51, step=2, description=\"face close_k\", continuous_update=False)\n",
    "tf_close_it_w = widgets.IntSlider(value=1,   min=1, max=6,  step=1, description=\"face close_it\", continuous_update=False)\n",
    "tf_pad_w      = widgets.FloatSlider(value=0.03, min=0.00, max=0.15, step=0.01,\n",
    "                                    description=\"face pad\", readout_format=\".2f\", continuous_update=False)\n",
    "tf_out_w      = widgets.IntSlider(value=650, min=200, max=900, step=10, description=\"face out_size\", continuous_update=False)\n",
    "\n",
    "# Pip counting params\n",
    "pip_ab_thr_w  = widgets.IntSlider(value=55,  min=10, max=100, step=1, description=\"pip ab_thr\", continuous_update=False)\n",
    "pip_L_lo_w    = widgets.IntSlider(value=165, min=50, max=245, step=1, description=\"pip L_lo\", continuous_update=False)\n",
    "pip_open_w    = widgets.IntSlider(value=3,   min=1, max=21, step=2, description=\"pip open_k\", continuous_update=False)\n",
    "pip_close_w   = widgets.IntSlider(value=9,   min=1, max=41, step=2, description=\"pip close_k\", continuous_update=False)\n",
    "pip_close_it_w = widgets.IntSlider(value=1,  min=1, max=6,  step=1, description=\"pip close_it\", continuous_update=False)\n",
    "border_w      = widgets.FloatSlider(value=0.045, min=0.0, max=0.12, step=0.005,\n",
    "                                    description=\"border_frac\", readout_format=\".3f\", continuous_update=False)\n",
    "min_pip_a_w   = widgets.FloatSlider(value=0.0012, min=0.0002, max=0.01, step=0.0002,\n",
    "                                    description=\"min_pip_area\", readout_format=\".4f\", continuous_update=False)\n",
    "max_pip_a_w   = widgets.FloatSlider(value=0.06, min=0.01, max=0.20, step=0.01,\n",
    "                                    description=\"max_pip_area\", readout_format=\".2f\", continuous_update=False)\n",
    "\n",
    "# Display toggles\n",
    "show_masks_w = widgets.Checkbox(value=True, description=\"show masks\")\n",
    "show_faces_w = widgets.Checkbox(value=True, description=\"show top faces & pips\")\n",
    "show_roi_color_w = widgets.Checkbox(value=True, description=\"show inner ROI (color)\")\n",
    "show_scored_w = widgets.Checkbox(value=True, description=\"print scored candidates\")\n",
    "\n",
    "# ======================\n",
    "# 3) Debug runner\n",
    "# ======================\n",
    "_cached = {\"frame_idx\": None, \"warped\": None}\n",
    "\n",
    "def run_debug(\n",
    "    frame,\n",
    "    region_ab_thr, region_L_min, region_L_q, region_open_k, region_close_k, region_close_it,\n",
    "    min_area_frac, max_area_frac, max_aspect, pad_frac,\n",
    "    use_rotated_rect, max_rot_aspect, min_extent, require_quad_like,\n",
    "    keep_top_k, max_to_score, score_with_pips,\n",
    "    face_ab_thr, face_L_min, face_L_q, face_open_k, face_close_k, face_close_it, face_pad, face_out_size,\n",
    "    pip_ab_thr, pip_L_lo, pip_open_k, pip_close_k, pip_close_it, border_frac, min_pip_area, max_pip_area,\n",
    "    show_masks, show_faces, show_roi_color, show_scored\n",
    "):\n",
    "    # Load & warp frame only when frame_idx changes\n",
    "    if _cached[\"frame_idx\"] != frame:\n",
    "        _cached[\"warped\"] = get_warped_frame(frame)\n",
    "        _cached[\"frame_idx\"] = frame\n",
    "    warped = _cached[\"warped\"]\n",
    "\n",
    "    region_cfg = DiceRegionCFG(\n",
    "        ab_thr=int(region_ab_thr),\n",
    "        L_min=int(region_L_min),\n",
    "        L_quantile=int(region_L_q),\n",
    "        open_k=int(region_open_k),\n",
    "        close_k=int(region_close_k),\n",
    "        close_iter=int(region_close_it),\n",
    "        min_area_frac=float(min_area_frac),\n",
    "        max_area_frac=float(max_area_frac),\n",
    "        max_aspect=float(max_aspect),\n",
    "        pad_frac=float(pad_frac),\n",
    "        keep_top_k=int(keep_top_k),\n",
    "\n",
    "        use_rotated_rect=bool(use_rotated_rect),\n",
    "        max_rot_aspect=float(max_rot_aspect),\n",
    "        min_extent=float(min_extent),\n",
    "        require_quad_like=bool(require_quad_like),\n",
    "\n",
    "        run_pips=True,                 # ✅ needed for scoring\n",
    "        score_with_pips=bool(score_with_pips),\n",
    "        max_candidates_to_score=int(max_to_score),\n",
    "\n",
    "        debug_keep_color_roi=True,\n",
    "    )\n",
    "\n",
    "    face_cfg = TopFaceCropCFG(\n",
    "        out_size=int(face_out_size),\n",
    "        upscale_long_side=int(face_out_size),\n",
    "        ab_thr=int(face_ab_thr),\n",
    "        L_min=int(face_L_min),\n",
    "        L_quantile=int(face_L_q),\n",
    "        open_k=int(face_open_k),\n",
    "        close_k=int(face_close_k),\n",
    "        close_iter=int(face_close_it),\n",
    "        pad_frac=float(face_pad),\n",
    "        debug=False,\n",
    "    )\n",
    "\n",
    "    pip_cfg = PipCountCFG(\n",
    "        ab_thr=int(pip_ab_thr),\n",
    "        L_lo=int(pip_L_lo),\n",
    "        open_k=int(pip_open_k),\n",
    "        close_k=int(pip_close_k),\n",
    "        close_iter=int(pip_close_it),\n",
    "        border_frac=float(border_frac),\n",
    "        min_area_frac=float(min_pip_area),\n",
    "        max_area_frac=float(max_pip_area),\n",
    "        debug=False,\n",
    "    )\n",
    "\n",
    "    det = detect_dice_in_inner_field(warped, inner_box, region_cfg=region_cfg, crop_cfg=face_cfg, pip_cfg=pip_cfg)\n",
    "    annot = draw_dice_on_warped(warped, det, inner_box=inner_box)\n",
    "\n",
    "    # Print quick summary\n",
    "    print(\"frame:\", frame)\n",
    "    print(\"inner_box:\", inner_box)\n",
    "    print(\"dice boxes (warped):\", det.boxes_warped)\n",
    "\n",
    "    # Print candidate scoring info from region stage\n",
    "    if show_scored and det.debug is not None and \"scored_candidates\" in det.debug:\n",
    "        print(\"\\nTop scored candidates (pre-final selection):\")\n",
    "        for d in det.debug[\"scored_candidates\"][: min(10, len(det.debug[\"scored_candidates\"]))]:\n",
    "            print(d)\n",
    "\n",
    "    # Compute pips for each detected crop with full debug (face + masks)\n",
    "    dice_vals = []\n",
    "    full = []\n",
    "    if det.crops is not None:\n",
    "        for crop in det.crops:\n",
    "            r = read_top_face_pips(crop, crop_cfg=face_cfg, pip_cfg=pip_cfg)\n",
    "            dice_vals.append(int(r[\"pip_count\"]))\n",
    "            full.append(r)\n",
    "    print(\"dice values:\", dice_vals)\n",
    "\n",
    "    # --- Display: annotated + masks + inner ROI color ---\n",
    "    if show_masks and det.debug is not None:\n",
    "        fig = plt.figure(figsize=(18, 6))\n",
    "        ax1 = fig.add_subplot(1, 4, 1)\n",
    "        ax1.set_title(\"annotated warped\")\n",
    "        ax1.imshow(cv2.cvtColor(annot, cv2.COLOR_BGR2RGB))\n",
    "        ax1.axis(\"off\")\n",
    "\n",
    "        ax2 = fig.add_subplot(1, 4, 2)\n",
    "        ax2.set_title(\"region mask (raw)\")\n",
    "        ax2.imshow(det.debug[\"mask_raw\"], cmap=\"gray\")\n",
    "        ax2.axis(\"off\")\n",
    "\n",
    "        ax3 = fig.add_subplot(1, 4, 3)\n",
    "        ax3.set_title(\"region mask (morph)\")\n",
    "        ax3.imshow(det.debug[\"mask_morph\"], cmap=\"gray\")\n",
    "        ax3.axis(\"off\")\n",
    "\n",
    "        ax4 = fig.add_subplot(1, 4, 4)\n",
    "        ax4.set_title(\"inner ROI (color)\")\n",
    "        if show_roi_color and \"inner_roi_bgr\" in det.debug:\n",
    "            ax4.imshow(cv2.cvtColor(det.debug[\"inner_roi_bgr\"], cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            ax4.imshow(np.zeros((10, 10, 3), dtype=np.uint8))\n",
    "        ax4.axis(\"off\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.imshow(cv2.cvtColor(annot, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        if show_roi_color and det.debug is not None and \"inner_roi_bgr\" in det.debug:\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.title(\"inner ROI (color)\")\n",
    "            plt.imshow(cv2.cvtColor(det.debug[\"inner_roi_bgr\"], cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "    # --- Show faces & pips per die (optional) ---\n",
    "    if show_faces and full:\n",
    "        for i, r in enumerate(full, start=1):\n",
    "            face = r[\"face\"]\n",
    "            face_mask = r[\"face_mask\"]\n",
    "            pips_mask = r[\"pips_mask\"]\n",
    "            plt.figure(figsize=(12, 3))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(f\"die {i} face (pips={r['pip_count']}, raw={r['raw_count']})\")\n",
    "            plt.imshow(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"face_mask\")\n",
    "            plt.imshow(face_mask, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"pips_mask\")\n",
    "            plt.imshow(pips_mask, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "# UI layout\n",
    "ui_left = widgets.VBox([\n",
    "    frame_idx_w,\n",
    "    show_masks_w, show_faces_w, show_roi_color_w, show_scored_w,\n",
    "    widgets.HTML(\"<b>Dice region (inner ROI)</b>\"),\n",
    "    ab_thr_w, L_min_w, L_q_w, open_k_w, close_k_w, close_it_w,\n",
    "    min_area_w, max_area_w, max_aspect_w, pad_frac_w,\n",
    "    widgets.HTML(\"<b>Square checks</b>\"),\n",
    "    use_rot_w, max_rot_aspect_w, min_extent_w, require_quad_w,\n",
    "    widgets.HTML(\"<b>Selection</b>\"),\n",
    "    keep_top_k_w, max_score_cand_w, score_with_pips_w,\n",
    "])\n",
    "\n",
    "ui_mid = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Top-face crop</b>\"),\n",
    "    tf_ab_thr_w, tf_L_min_w, tf_L_q_w, tf_open_w, tf_close_w, tf_close_it_w,\n",
    "    tf_pad_w, tf_out_w,\n",
    "])\n",
    "\n",
    "ui_right = widgets.VBox([\n",
    "    widgets.HTML(\"<b>Pip counting</b>\"),\n",
    "    pip_ab_thr_w, pip_L_lo_w, pip_open_w, pip_close_w, pip_close_it_w,\n",
    "    border_w, min_pip_a_w, max_pip_a_w,\n",
    "])\n",
    "\n",
    "controls = widgets.HBox([ui_left, ui_mid, ui_right])\n",
    "display(controls)\n",
    "\n",
    "out = widgets.interactive_output(\n",
    "    run_debug,\n",
    "    dict(\n",
    "        frame=frame_idx_w,\n",
    "        region_ab_thr=ab_thr_w,\n",
    "        region_L_min=L_min_w,\n",
    "        region_L_q=L_q_w,\n",
    "        region_open_k=open_k_w,\n",
    "        region_close_k=close_k_w,\n",
    "        region_close_it=close_it_w,\n",
    "        min_area_frac=min_area_w,\n",
    "        max_area_frac=max_area_w,\n",
    "        max_aspect=max_aspect_w,\n",
    "        pad_frac=pad_frac_w,\n",
    "\n",
    "        use_rotated_rect=use_rot_w,\n",
    "        max_rot_aspect=max_rot_aspect_w,\n",
    "        min_extent=min_extent_w,\n",
    "        require_quad_like=require_quad_w,\n",
    "\n",
    "        keep_top_k=keep_top_k_w,\n",
    "        max_to_score=max_score_cand_w,\n",
    "        score_with_pips=score_with_pips_w,\n",
    "\n",
    "        face_ab_thr=tf_ab_thr_w,\n",
    "        face_L_min=tf_L_min_w,\n",
    "        face_L_q=tf_L_q_w,\n",
    "        face_open_k=tf_open_w,\n",
    "        face_close_k=tf_close_w,\n",
    "        face_close_it=tf_close_it_w,\n",
    "        face_pad=tf_pad_w,\n",
    "        face_out_size=tf_out_w,\n",
    "\n",
    "        pip_ab_thr=pip_ab_thr_w,\n",
    "        pip_L_lo=pip_L_lo_w,\n",
    "        pip_open_k=pip_open_w,\n",
    "        pip_close_k=pip_close_w,\n",
    "        pip_close_it=pip_close_it_w,\n",
    "        border_frac=border_w,\n",
    "        min_pip_area=min_pip_a_w,\n",
    "        max_pip_area=max_pip_a_w,\n",
    "\n",
    "        show_masks=show_masks_w,\n",
    "        show_faces=show_faces_w,\n",
    "        show_roi_color=show_roi_color_w,\n",
    "        show_scored=show_scored_w,\n",
    "    )\n",
    ")\n",
    "display(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
